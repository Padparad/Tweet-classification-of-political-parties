{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59c4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load your training dataset\n",
    "train_df = pd.read_csv(\"data_clean.csv\")\n",
    "test_df = pd.read_csv(\"test_clean.csv\")\n",
    "\n",
    "columns_to_drop = ['tweet_chars', 'tweet_words', 'hashtag_chars', 'hashtag_words', 'text_clean_chars', 'text_clean_words']\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Preprocessing\n",
    "train_df['text_clean'].fillna('', inplace=True)\n",
    "train_df['country_user'].fillna('Unknown', inplace=True)\n",
    "train_df['gender_user'].fillna('Unknown', inplace=True)\n",
    "train_df['sentiment_score'].fillna(0, inplace=True)  # Replace NaN with a default value\n",
    "train_df['hashtags'].fillna('', inplace=True)  # Replace NaN with empty strings\n",
    "# Preprocessing (Make sure to handle new categories as discussed above)\n",
    "test_df['text_clean'].fillna('', inplace=True)\n",
    "test_df['country_user'].fillna('Unknown', inplace=True)\n",
    "test_df['gender_user'].fillna('Unknown', inplace=True)\n",
    "test_df['sentiment_score'].fillna(0, inplace=True)\n",
    "test_df['hashtags'].fillna('', inplace=True)\n",
    "\n",
    "# TFIDF Vectorization for 'text_clean'\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=13080)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(train_df['text_clean'].values.astype('U'))\n",
    "X_tfidf_test = tfidf_vectorizer.transform(test_df['text_clean'].values.astype('U'))\n",
    "\n",
    "# Vectorization for 'hashtags'\n",
    "# You can choose between TfidfVectorizer and CountVectorizer\n",
    "hashtag_vectorizer = TfidfVectorizer()\n",
    "X_hashtags = hashtag_vectorizer.fit_transform(train_df['hashtags'].values.astype('U'))\n",
    "\n",
    "# One-hot Encoding for 'country_user' and 'gender_user'\n",
    "onehot_encoder = OneHotEncoder()\n",
    "X_country = onehot_encoder.fit_transform(train_df[['country_user']])\n",
    "X_country_test = onehot_encoder.fit_transform(test_df[['country_user']])\n",
    "X_gender = onehot_encoder.fit_transform(train_df[['gender_user']])\n",
    "X_gender_test = onehot_encoder.transform(test_df[['gender_user']])\n",
    "\n",
    "\n",
    "# Apply weighting to the country feature\n",
    "country_weight = 5  # This is the weighting factor for the country feature\n",
    "X_country_weighted = X_country.multiply(country_weight)\n",
    "gender_weight = 2\n",
    "X_gender_weighted = X_gender.multiply(gender_weight)\n",
    "\n",
    "\n",
    "# Normalize or Standardize the sentiment score\n",
    "scaler = StandardScaler()\n",
    "X_sentiment = scaler.fit_transform(train_df[['sentiment_score']])\n",
    "\n",
    "# Combine all features \n",
    "X_combined = hstack([X_tfidf, X_country_weighted, X_gender_weighted, csr_matrix(X_sentiment), X_hashtags])\n",
    "\n",
    "# Encode the target variable\n",
    "y = train_df['pol_spec_user'].astype('category').cat.codes\n",
    "target_labels = train_df['pol_spec_user'].astype('category').cat.categories\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa077f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=150, max_depth=4000, min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "rf_classifier.fit(X_combined, y)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate the classifier\n",
    "# accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "# classification_rep_rf = classification_report(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670862c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69     21099\n",
      "           1       0.77      0.58      0.66       153\n",
      "           2       0.72      0.83      0.77     34943\n",
      "           3       0.74      0.70      0.72     25250\n",
      "\n",
      "    accuracy                           0.74     81445\n",
      "   macro avg       0.75      0.68      0.71     81445\n",
      "weighted avg       0.74      0.74      0.73     81445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_rep_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefaf090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply weighting to the transformed features\n",
    "X_country_weighted_test = X_country_test.multiply(country_weight)\n",
    "X_gender_weighted_test = X_gender_test.multiply(gender_weight)\n",
    "\n",
    "# Apply weighting and standardize sentiment scores\n",
    "X_country_weighted_test = X_country_test.multiply(country_weight)\n",
    "X_sentiment_test = scaler.transform(test_df[['sentiment_score']])\n",
    "X_hashtags_test = hashtag_vectorizer.transform(test_df['hashtags'].values.astype('U'))\n",
    "\n",
    "# Combine all features for the test set\n",
    "X_combined_test = hstack([X_tfidf_test, X_country_weighted_test, X_gender_weighted_test, csr_matrix(X_sentiment_test), X_hashtags_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea632b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_classifier.predict(X_combined_test)\n",
    "\n",
    "# Load the submission file\n",
    "submission = pd.read_csv('submission_north_europe.csv')\n",
    "\n",
    "predicted_labels = target_labels[y_pred_rf]\n",
    "# Assign the predicted labels to the appropriate column in the submission file\n",
    "submission['pol_spec_user'] = predicted_labels\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission74.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e4417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bd0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
